***Alexnext Benchmarking***
Usage ./run_gpu_nmt_l5.sh <typeofgpu> --> e.g: ./run_gpu_nmt_l5.sh geforce_gtx_maxwell
**batch size 1**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 4666.2769317627ms	
**batch size 16**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 5044.2819595337ms	
**batch size 32**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 5183.1879615784ms	
**batch size 64**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 5023.3330726624ms	
**batch size 128**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 6791.2850379944ms	
**batch size 256**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 13928.920984268ms	
**batch size 512**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 24649.119853973ms	
**batch size 750**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 66730.620145798ms	
Batch size of 750 is the largest that ran on the 12GB GPU
