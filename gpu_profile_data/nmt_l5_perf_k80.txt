***Alexnext Benchmarking***
Usage ./run_gpu_nmt_l5.sh <typeofgpu> --> e.g: ./run_gpu_nmt_l5.sh geforce_gtx_maxwell
**batch size 1**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 3177.2048473358ms	
**batch size 16**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 9737.1909618378ms	
**batch size 32**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 9847.0921516418ms	
**batch size 64**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 10383.611917496ms	
**batch size 128**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 15665.201187134ms	
**batch size 256**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 30582.88192749ms	
**batch size 512**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 54852.22697258ms	
**batch size 750**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.CudaTensor	
GPU Time: 77147.134065628ms	
Batch size of 750 is the largest that ran on the 12GB GPU
