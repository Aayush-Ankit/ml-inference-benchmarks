***wlm_anotherLSTM Benchmarking***
Usage ./run_gpu_wlm_anotherLSTM.sh <typeofgpu> --> e.g: ./run_gpu_wlm_anotherLSTM.sh geforce_gtx_maxwell
**batch size 1**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 133.75401496887ms	
**batch size 16**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 144.23489570618ms	
**batch size 32**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 153.80787849426ms	
**batch size 64**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 149.48487281799ms	
**batch size 128**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 147.00889587402ms	
**batch size 256**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 152.81391143799ms	
**batch size 512**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 269.17815208435ms	
**batch size 1024**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 1104.6278476715ms	
**batch size 2048**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 2155.797958374ms	
**batch size 4096**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 7132.8780651093ms	
**wlm_anotherLSTM can run upto 4096 for a 12GB GPU***
