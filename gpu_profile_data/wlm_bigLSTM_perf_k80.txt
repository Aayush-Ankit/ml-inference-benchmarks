***wlm_bigLSTM Benchmarking***
Usage ./run_gpu_wlm_bigLSTM.sh <typeofgpu> --> e.g: ./run_gpu_wlm_bigLSTM.sh geforce_gtx_maxwell
**batch size 1**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 308.82215499878ms	
**batch size 16**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 778.21516990662ms	
**batch size 32**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 804.41689491272ms	
**batch size 64**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 775.06303787231ms	
**batch size 128**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 997.60508537292ms	
**batch size 256**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 1999.9670982361ms	
**batch size 512**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 3765.0148868561ms	
**batch size 1024**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 7784.6500873566ms	
**batch size 2048**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 15500.128030777ms	
**batch size 3800**
Number of parameters	855703552	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SeqLSTMP
  (2): nn.SeqLSTMP
}
==> Type is torch.CudaTensor	
GPU Time: 27117.105960846ms	
**wlm_bigLSTM can run upto 3800 for a 12GB GPU***
