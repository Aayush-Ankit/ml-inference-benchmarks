***nmt_l5 Benchmarking***
Usage ./run_cpu_nmt_l5.sh <numberofthreads> --> e.g: ./run_cpu_nmt_l5.sh 4
**batch size 1**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.FloatTensor	
CPU Time: 400169.83795166ms	
**batch size 16**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.FloatTensor	
CPU Time: 509029.95896339ms	
**batch size 32**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.FloatTensor	
CPU Time: 619228.73401642ms	
**batch size 64**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.FloatTensor	
CPU Time: 823577.84891129ms	
**batch size 128**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.FloatTensor	
CPU Time: 1231814.9600029ms	
**batch size 256**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.FloatTensor	
CPU Time: 390138.45586777ms	
**batch size 512**
Number of parameters	124927040	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
}
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]
  (1): nn.SeqLSTM
  (2): nn.SeqLSTM
  (3): nn.SeqLSTM
  (4): nn.SeqLSTM
  (5): nn.SeqLSTM
  (6): nn.Sequencer @ nn.Recursor @ nn.Linear(1024 -> 40000)
}
==> Type is torch.FloatTensor	
