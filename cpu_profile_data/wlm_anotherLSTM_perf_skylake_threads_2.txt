***wlm_anotherLSTM Benchmarking***
Usage ./run_cpu_wlm_anotherLSTM.sh <numberofthreads> --> e.g: ./run_cpu_wlm_anotherLSTM.sh 4
**batch size 1**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 54226.783037186ms	
**batch size 16**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 63758.081912994ms	
**batch size 32**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 67081.918001175ms	
**batch size 64**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 81912.9550457ms	
**batch size 128**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 108975.46005249ms	
**batch size 256**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 21573.443889618ms	
**batch size 512**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 35140.620946884ms	
**batch size 1024**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 65457.684993744ms	
**batch size 2048**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 112062.56484985ms	
**batch size 4096**
Number of parameters	553680896	
nn.Sequential {
  [input -> (1) -> output]
  (1): nn.SeqLSTMP
}
==> Type is torch.FloatTensor	
CPU Time: 233978.31296921ms	
